# Info Finder - Environment Configuration
# Copy this file to .env and update with your values
# 
# NOTE: Groq API keys are now stored per-user in the database.
# Users provide their own API key during signup.

# =============================================================================
# LLM Provider Configuration
# =============================================================================

# Default LLM provider: "groq" (free cloud) or "ollama" (free local backup)
LLM_PROVIDER=groq

# =============================================================================
# Groq Configuration (Primary - Free tier)
# =============================================================================

# Groq API keys are now PER-USER (stored in database during signup)
# Get your free API key at: https://console.groq.com/keys
# 
# Each user provides their own key during registration.
# This ensures:
#   - No server-side API costs
#   - Scalability as users grow
#   - Users control their own usage/limits

# Available models: llama-3.1-8b-instant, llama-3.1-70b-versatile, mixtral-8x7b-32768
GROQ_MODEL=llama-3.1-8b-instant

# =============================================================================
# Ollama Configuration (Backup - Local/Offline)
# =============================================================================

# Ollama is available as a backup option for offline/local use
# Install from: https://ollama.ai/

# Ollama server URL (default: http://localhost:11434)
OLLAMA_BASE_URL=http://localhost:11434

# Ollama model to use (e.g., llama3.1, mistral, codellama)
# Run: ollama pull llama3.1
OLLAMA_MODEL=llama3.1

# =============================================================================
# Application Settings (Optional)
# =============================================================================

# Streamlit server settings
# STREAMLIT_SERVER_PORT=8501
# STREAMLIT_SERVER_HEADLESS=true
